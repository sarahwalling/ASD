{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While researching decision trees, I happened upon a summary of the CART algorithm and was intrigued by the description of this recursive method. My understanding (and approach to making my decision tree) was focused on two major things. I wanted to use a weighted gini score - more specifically, the average of the Gini impurity of the children, weighted by their population - and a recursive, non-greedy approach. \n",
    "\n",
    "The method that was the hardest to figure out was how to compute the “best split” for each node in the tree. (“Best” meaning the average impurity of the two children, weighted by their population, is less than the impurity of the current node, and is the smallest score possible for the next step.) The goal was to recursively compute the weighted Gini of the two children all the way down the tree before locking in the top node decision, but I was never able to get that approach working correctly. \n",
    "\n",
    "My next idea was to avoid a quadratic runtime by iteratively looping through the sorted feature values as possible “thresholds” for a split (based on its gini score), while keeping track of the number of samples per class on the left and on the right and just incrementing/decrementing them by 1 after looking at each threshold. I compute the gini impurity of the split generated by that particular threshold, and return the one with the smallest impurity. This method is not recursive itself, but is called many times while recursively growing the tree. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import Bunch\n",
    "import tree\n",
    "\n",
    "class Decision_Tree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = DEPTH\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes = 2\n",
    "        self.n_features = X.shape[1]\n",
    "        self.n_features = X.shape[1]\n",
    "        self.tree = self.grow_tree(X, y)\n",
    "\n",
    "    def predict_class(self, X): #general class prediction for whole list - calls single method below\n",
    "        return [self.predict(inputs) for inputs in X]\n",
    "\n",
    "    def predict(self, inputs): #predict class for one node\n",
    "        node = self.tree\n",
    "        while node.left:\n",
    "            if inputs[node.feature_index] < node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.predicted_class\n",
    "\n",
    "    def gini(self, y):  #compute gini impurity\n",
    "        m = y.size\n",
    "        return 1.0 - sum((np.sum(y == c) / m) ** 2 for c in range(self.n_classes))\n",
    "\n",
    "    def best_split(self, X, y): #find the best split, i.e. average weighted impurity is minimized as much as possible\n",
    "        #Process:\n",
    "        # 1. Iterate through the sorted feature values as possible thresholds\n",
    "        # 2. Keep track of the number of samples per class on the left and on the right\n",
    "        # 3. Increment/decrement them by 1 after each threshold.\n",
    "        m = y.size\n",
    "        if m <= 1: #need at least two elements to split\n",
    "            return None, None\n",
    "\n",
    "        #count up number in each class\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes)]\n",
    "\n",
    "        #compute gini score of current node\n",
    "        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
    "        best_idx, best_thr = None, None\n",
    "\n",
    "        #walk through all features\n",
    "        for idx in range(self.n_features):\n",
    "            #sort values along current feature\n",
    "            thresholds,classes = X[:, idx], y[:, 0]\n",
    "\n",
    "            #compute iteratively\n",
    "            num_left = [0] * self.n_classes\n",
    "            num_right = num_parent.copy()\n",
    "            for i in range(1, m):  # possible split positions\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                gini_left = 1.0 - sum(\n",
    "                    (num_left[x] / i) ** 2 for x in range(self.n_classes)\n",
    "                )\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes)\n",
    "                )\n",
    "\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "\n",
    "                if thresholds[i] == thresholds[i - 1]: #don't want to split at identical values\n",
    "                    continue\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2  # midpoint\n",
    "        return best_idx, best_thr\n",
    "\n",
    "    def grow_tree(self, X, y, depth=0):\n",
    "        count = 0\n",
    "        while count <= N_FEATURES:\n",
    "            count = count + 1\n",
    "            #build decision tree by recursively finding the best split\n",
    "            num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes)]\n",
    "            predicted_class = np.argmax(num_samples_per_class)\n",
    "            node = tree.Tree_node(\n",
    "                gini=self.gini(y),\n",
    "                num_samples=y.size,\n",
    "                num_samples_per_class=num_samples_per_class,\n",
    "                predicted_class=predicted_class,\n",
    "            )\n",
    "\n",
    "            if depth < self.max_depth:\n",
    "                index, threshold = self.best_split(X, y)\n",
    "                if index is not None:\n",
    "                    indices_left = X[:, index] < threshold\n",
    "                    X_left, y_left = X[indices_left], y[indices_left]\n",
    "                    X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                    node.feature_index = index\n",
    "                    node.threshold = threshold\n",
    "                    node.left = self.grow_tree(X_left, y_left, depth + 1)\n",
    "                    node.right = self.grow_tree(X_right, y_right, depth + 1)\n",
    "            #print(node.feature_index )\n",
    "            return node\n",
    "\n",
    "    def printTree(self, feature_names, class_names, show_details=False):\n",
    "        self.tree.print_tree(feature_names, class_names, show_details)\n",
    "        \n",
    "        \n",
    "def test_accuracy(pred_score, predlabels):\n",
    "    print(N_FEATURES, 'features')\n",
    "    y_true = predlabels\n",
    "    cm = confusion_matrix([1-x for x in y_true], [1-int(x > 0.5) for x in pred_score])\n",
    "    print('Sensitivity: {}'.format(float(cm[0][0])/(cm[0][0]+cm[0][1])))\n",
    "    print('Specificity: {}'.format(float(cm[1][1])/(cm[1][1]+cm[1][0])))\n",
    "    recall = ((cm[0][0])/(cm[0][0]+cm[0][1]) + (cm[1][1])/(cm[1][1]+cm[1][0]))/2\n",
    "    print('Recall: {}'.format(float(recall)))\n",
    "    print('Confusion matrix:')\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPTH = 10\n",
    "N_FEATURES = 5\n",
    "\n",
    "attributes_train = ['question1', 'question2', 'question3', 'question4', 'question5', 'question6', 'question7',\n",
    "                    'question8', 'question9', 'question10', 'question11', 'question12', 'question13', 'question14',\n",
    "                    'question15', 'question16', 'question17', 'question18', 'question19', 'question20',\n",
    "                    'question21', 'question22', 'question23', 'question24', 'question25', 'question26',\n",
    "                    'question27', 'question28', 'question29', 'question30', 'diag']\n",
    "X_train_labels = ['question1', 'question2', 'question3', 'question4', 'question5', 'question6', 'question7',\n",
    "                    'question8', 'question9', 'question10', 'question11', 'question12', 'question13', 'question14',\n",
    "                    'question15', 'question16', 'question17', 'question18', 'question19', 'question20',\n",
    "                    'question21', 'question22', 'question23', 'question24', 'question25', 'question26',\n",
    "                    'question27', 'question28', 'question29', 'question30']\n",
    "y_train_labels = ['diag']\n",
    "\n",
    "attributes_test = ['question1', 'question2', 'question3', 'question4', 'question5', 'question6', 'question7',\n",
    "                   'question8', 'question9', 'question10', 'question11', 'question12', 'question13', 'question14',\n",
    "                   'question15', 'question16', 'question17', 'question18', 'question19', 'question20', 'question21',\n",
    "                   'question22', 'question23', 'question24', 'question25', 'question26', 'question27', 'question28',\n",
    "                   'question29', 'question30', 'ASD']\n",
    "X_test_labels = ['question1', 'question2', 'question3', 'question4', 'question5', 'question6', 'question7',\n",
    "                   'question8', 'question9', 'question10', 'question11', 'question12', 'question13', 'question14',\n",
    "                   'question15', 'question16', 'question17', 'question18', 'question19', 'question20', 'question21',\n",
    "                   'question22', 'question23', 'question24', 'question25', 'question26', 'question27', 'question28',\n",
    "                   'question29', 'question30']\n",
    "y_test_labels = ['ASD']\n",
    "\n",
    "train, test = pd.read_csv('primary_dataset.csv', usecols=attributes_train), pd.read_csv('validation_dataset.csv',usecols=attributes_test)\n",
    "\n",
    "train_set = pd.DataFrame(train)\n",
    "#print(train_set)\n",
    "train_set = Bunch(\n",
    "    data=train.loc[:, X_train_labels],\n",
    "    target=train.loc[:, y_train_labels],\n",
    "    feature_names = [\"question {}\".format(i) for i in range(1, 31)],\n",
    "    target_names = [\"diag {}\".format(i) for i in range(0, 2)],\n",
    "    hide_details=False\n",
    ")\n",
    "\n",
    "X_train, y_train = train_set.data.to_numpy(), train_set.target.to_numpy()\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]=='asd':\n",
    "        y_train[i] = 1\n",
    "    else:\n",
    "        y_train[i] = 0\n",
    "# X_train = X_train.loc[:, X_train.columns != 'asd']\n",
    "# y_train = pd.DataFrame(X_train.loc(X_train.columns == 'asd'))\n",
    "\n",
    "X_test = pd.DataFrame(test)\n",
    "X_test = Bunch(\n",
    "    data=test.loc[:, X_test_labels],\n",
    "    target=test.loc[:, y_test_labels]\n",
    ")\n",
    "X_test, y_test = X_test.data, X_test.target\n",
    "\n",
    "\n",
    "clf = Decision_Tree(max_depth=10)\n",
    "clf.fit(X_train, y_train)\n",
    "#test_accuracy(list(clf.fit(X_train, y_train)), y_train)\n",
    "\n",
    "#clf.printTree(\n",
    "#    list(train_set.feature_names),\n",
    "#    list(train_set.target_names),\n",
    "#    not train_set.hide_details,\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "There are definitely bugs in the decision tree code, and the optimization I tried to write into it didn't lend itself well to being adapted to the random forest... so I essentially had to start from scratch with a simpler decision tree to use in the random forest. (I also moved away from trying to use Pandas dataframe stuff because trying to learn all their methods was really slowing me down.)\n",
    "\n",
    "I also added k-folds cross validation so I could compare it to how the separate training and test sets perform. Since I never implemented the grouping/voting on child IDs in the dataset, and instead just treat each entry separately, k-folds seemed like an interesting compromise between the two approaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the best split point, I evaluate the cost of each value in the training dataset for each input variable. get_split takes a fixed number of input features from the dataset (chosen randomly and without replacement) to evaluate, only needing to look at each attribute once when looking for the split point with the lowest cost.\n",
    "Two helper functions are used here: test_split is used to split the dataset at a possible split point, and gini_index is used to evaluate the cost of a given split by the group created. \n",
    "\n",
    "In essence: a list of features is made by randomly selecting indices (of features) and putting them in a list, which we then go through and evaluate as possible split points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best split point\n",
    "def get_split(dataset, n_features):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    new_index, new_value, new_score, new_groups = 999, 999, 999, None\n",
    "    features = list()\n",
    "    while len(features) < n_features:\n",
    "        index = randrange(len(dataset[0]) - 1)\n",
    "        if index not in features:\n",
    "            features.append(index)\n",
    "    for index in features:\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < new_score:\n",
    "                new_index, new_value, new_score, new_groups = index, row[index], gini, groups\n",
    "    return {'index': new_index, 'value': new_value, 'groups': new_groups}\n",
    "\n",
    "# split the dataset based on attribute and attribute value\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "# calculate the gini impurity\n",
    "def gini_index(groups, classes):\n",
    "    #count all samples at the split point\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "\n",
    "    #sum the weighted gini index for each group\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        # don't divide by 0\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        # calculate the score for the group from the score for each class\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        # weight the score by group size\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I said, I used k-fold cross validation methods to look at some form of random grouping with my model. Obviously, this means I have to split the dataset into k folds and then evaluate across the k models. \n",
    "Otherwise, it doesn't vary much from the method evaluating with the separate training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        split.append(fold)\n",
    "    return split\n",
    "\n",
    "# evaluate using the k-folds cross validation split\n",
    "def evaluate_folds(dataset, n_folds, max_depth, min_size, sample_size, n_trees, n_features):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = random_forest(train_set, test_set, max_depth, min_size, sample_size, n_trees, n_features)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = get_accuracy(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores\n",
    "\n",
    "# evaluate with separate training and test datasets instead of k-folds\n",
    "# this currently requires test set and training set to be same size\n",
    "def evaluate_separate(dataset, test_set, max_depth, min_size, sample_size, n_trees, n_features):\n",
    "    scores = list()\n",
    "    predicted = random_forest(dataset, test_set, max_depth, min_size, sample_size, n_trees, n_features)\n",
    "    actual = [row[-1] for row in dataset]\n",
    "    accuracy = get_accuracy(actual, predicted)\n",
    "    scores.append(accuracy)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm still trying to use something similar to the CART algorithm, but adapted for bagging. The methods to_leaf, split, and build_tree work together to create a single decision tree. This is still a \"greedy\" method, building the trees on asking the \"best\" questions (as informed by gini score) instead of completely random building of a tree.  \n",
    "Predict makes a prediction on a single decision tree, subsample makes (obviously) a subsample of the training data, and bagging_predict makes a prediction on the whole group (list) of decision trees.  \n",
    "Random_forest actually powers all of this: first creating a bunch of decision trees from the subsamples of the training data, and then uses that bunch to make the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_leaf(group):\n",
    "    leaves = [row[-1] for row in group]\n",
    "    return max(set(leaves), key=leaves.count)\n",
    "\n",
    "\n",
    "# create children splits for a node, or make leaf\n",
    "def split(node, max_depth, min_size, n_features, depth):\n",
    "    left, right = node['groups']\n",
    "    del (node['groups'])\n",
    "    #check for no split\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_leaf(left + right)\n",
    "        return\n",
    "\n",
    "    #check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_leaf(left), to_leaf(right)\n",
    "        return\n",
    "\n",
    "    #do left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_leaf(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left, n_features)\n",
    "        split(node['left'], max_depth, min_size, n_features, depth + 1)\n",
    "\n",
    "    #do right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_leaf(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right, n_features)\n",
    "        split(node['right'], max_depth, min_size, n_features, depth + 1)\n",
    "        \n",
    "        \n",
    "# build a single decision tree\n",
    "def build_tree(train, max_depth, min_size, n_features):\n",
    "    root = get_split(train, n_features)\n",
    "    split(root, max_depth, min_size, n_features, 1)\n",
    "    return root\n",
    "\n",
    "\n",
    "# make a prediction with a single decision tree\n",
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "\n",
    "# create a random sample (with replacement)\n",
    "def subsample(dataset, ratio):\n",
    "    sample = list()\n",
    "    n_sample = round(len(dataset) * ratio)\n",
    "    while len(sample) < n_sample:\n",
    "        index = randrange(len(dataset))\n",
    "        sample.append(dataset[index])\n",
    "    return sample\n",
    "\n",
    "\n",
    "# make a prediction with a list of bagged trees\n",
    "def bagging_predict(trees, row):\n",
    "    predictions = [predict(tree, row) for tree in trees]\n",
    "    return max(set(predictions), key=predictions.count)\n",
    "\n",
    "\n",
    "# random forest - calls helper methods to actually build it\n",
    "def random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features):\n",
    "    trees = list()\n",
    "    for i in range(n_trees):\n",
    "        sample = subsample(train, sample_size)\n",
    "        tree = build_tree(sample, max_depth, min_size, n_features)\n",
    "        trees.append(tree)\n",
    "    predictions = [bagging_predict(trees, row) for row in test]\n",
    "    return (predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course, there is some work to do with converting the string classes to int, and calculating all the accuracy metrics when everything is done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_class_to_int(dataset, column):\n",
    "    for row in dataset:\n",
    "        if row[column] == 'asd':\n",
    "            row[column] = 1\n",
    "        else:\n",
    "            row[column] = 0\n",
    "            \n",
    "\n",
    "# calculate accuracy metrics\n",
    "def get_accuracy(actual, predicted):\n",
    "    confusion_matrix = a = [[0 for x in range(2)] for y in range(2)]\n",
    "    correct = 0\n",
    "    scores = list()\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == 0:\n",
    "            if predicted[i] == 0:\n",
    "                confusion_matrix[0][0] = confusion_matrix[0][0] + 1\n",
    "            if predicted[i] == 1:\n",
    "                confusion_matrix[0][1] = confusion_matrix[0][1] + 1\n",
    "        if actual[i] == 1:\n",
    "            if predicted[i] == 0:\n",
    "                confusion_matrix[1][0] = confusion_matrix[1][0] + 1\n",
    "            if predicted[i] == 1:\n",
    "                confusion_matrix[1][1] = confusion_matrix[1][1] + 1\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    sensitivity = float(confusion_matrix[0][0] / (confusion_matrix[0][0] + confusion_matrix[1][0])) * 100\n",
    "    specificity = float(confusion_matrix[1][1] / (confusion_matrix[1][1] + confusion_matrix[0][1])) * 100\n",
    "    accuracy = correct / float(len(actual)) * 100.0\n",
    "    scores.append(sensitivity)\n",
    "    scores.append(specificity)\n",
    "    scores.append(accuracy)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together, here's results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trees: 5\n",
      "\n",
      "Features: 3\n",
      "Mean Sensitivity: 75.812%\n",
      "Mean Specificity: 91.368%\n",
      "Mean Accuracy: 85.799%\n",
      "\n",
      "Features: 4\n",
      "Mean Sensitivity: 78.499%\n",
      "Mean Specificity: 92.386%\n",
      "Mean Accuracy: 87.377%\n",
      "\n",
      "Features: 5\n",
      "Mean Sensitivity: 78.420%\n",
      "Mean Specificity: 88.505%\n",
      "Mean Accuracy: 85.404%\n",
      "\n",
      "Features: 6\n",
      "Mean Sensitivity: 75.680%\n",
      "Mean Specificity: 91.063%\n",
      "Mean Accuracy: 85.799%\n",
      "\n",
      "Features: 7\n",
      "Mean Sensitivity: 79.220%\n",
      "Mean Specificity: 91.684%\n",
      "Mean Accuracy: 87.574%\n",
      "\n",
      "Features: 8\n",
      "Mean Sensitivity: 81.459%\n",
      "Mean Specificity: 90.136%\n",
      "Mean Accuracy: 86.982%\n",
      "\n",
      "Features: 9\n",
      "Mean Sensitivity: 78.362%\n",
      "Mean Specificity: 90.197%\n",
      "Mean Accuracy: 86.391%\n",
      "\n",
      "Features: 10\n",
      "Mean Sensitivity: 75.217%\n",
      "Mean Specificity: 89.897%\n",
      "Mean Accuracy: 85.010%\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed(5)\n",
    "attributes_train = ['question1', 'question2', 'question3', 'question4', 'question5', 'question6', 'question7',\n",
    "                    'question8', 'question9', 'question10', 'question11', 'question12', 'question13', 'question14',\n",
    "                    'question15', 'question16', 'question17', 'question18', 'question19', 'question20',\n",
    "                    'question21', 'question22', 'question23', 'question24', 'question25', 'question26',\n",
    "                    'question27', 'question28', 'question29', 'question30', 'diag']\n",
    "\n",
    "attributes_test = ['question1', 'question2', 'question3', 'question4', 'question5', 'question6', 'question7',\n",
    "                   'question8', 'question9', 'question10', 'question11', 'question12', 'question13', 'question14',\n",
    "                   'question15', 'question16', 'question17', 'question18', 'question19', 'question20', 'question21',\n",
    "                   'question22', 'question23', 'question24', 'question25', 'question26', 'question27', 'question28',\n",
    "                   'question29', 'question30', 'ASD']\n",
    "\n",
    "train, test = pd.read_csv('primary_dataset.csv', usecols=attributes_train), pd.read_csv('validation_dataset.csv', usecols=attributes_test)\n",
    "dataset = train.values.tolist()\n",
    "test_set = test.values.tolist()\n",
    "\n",
    "# convert class column to integers\n",
    "convert_class_to_int(dataset, len(dataset[0]) - 1)\n",
    "\n",
    "# evaluate algorithm\n",
    "n_folds = 3\n",
    "max_depth = 10\n",
    "min_size = 1\n",
    "sample_size = 1.0\n",
    "n_trees = 5 #change here to run on 500 trees or whatever other number you want to try\n",
    "mean_sensitivity = list()\n",
    "mean_specificity = list()\n",
    "mean_accuracy = list()\n",
    "num_features = [3,4,5,6,7,8,9,10]\n",
    "\n",
    "print('Trees: %d\\n' % n_trees)\n",
    "for n_features in num_features:\n",
    "    scores = evaluate_folds(dataset, n_folds, max_depth, min_size, sample_size, n_trees, n_features)\n",
    "    #scores = evaluate_separate(dataset, test_set, max_depth, min_size, sample_size, n_trees, n_features)\n",
    "    sensitivity = list()\n",
    "    specificity = list()\n",
    "    accuracy = list()\n",
    "    print('Features: %d' % n_features)\n",
    "    for row in scores:\n",
    "        sensitivity.append(row[0])\n",
    "        specificity.append(row[1])\n",
    "        accuracy.append(row[2])\n",
    "    print('Mean Sensitivity: %.3f%%' % (sum(sensitivity) / float(len(sensitivity))))\n",
    "    print('Mean Specificity: %.3f%%' % (sum(specificity) / float(len(specificity))))\n",
    "    print('Mean Accuracy: %.3f%%\\n' % (sum(accuracy) / float(len(accuracy))))\n",
    "    mean_sensitivity.append((sum(sensitivity) / float(len(sensitivity))))\n",
    "    mean_specificity.append(sum(specificity) / float(len(specificity)))\n",
    "    mean_accuracy.append(sum(accuracy) / float(len(accuracy)))\n",
    "\n",
    "plt.plot(num_features, mean_accuracy, linestyle='-', linewidth=3, color='tab:blue', label='Accuracy')\n",
    "plt.plot(num_features, mean_specificity, linestyle=':', linewidth=3, color='olivedrab', label=\"Specificity\")\n",
    "plt.plot(num_features, mean_sensitivity, linestyle='--', linewidth=3, color='crimson', label=\"Sensitivity\")\n",
    "plt.xlabel(\"Number of Features\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.title(\"Performance (5 trees)\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.grid(color='lightgrey')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed in the last meeting, my specificity vs sensitivity numbers suggest that there is definitely some overfitting, probably due to the greedy building of the trees. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
